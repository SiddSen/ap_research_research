{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SiddSen/ap_research_research/blob/main/TF_slim.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4G-4vwN8HgTF"
      },
      "outputs": [],
      "source": [
        "!pip install tf_slim\n",
        "!pip install roboflow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/tensorflow/models/"
      ],
      "metadata": {
        "id": "Wi5uCgG4U0FF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd models/research/slim"
      ],
      "metadata": {
        "id": "XpB4XFLfVHjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%mkdir dataset"
      ],
      "metadata": {
        "id": "W344SIEK2RtX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DOWNLOAD_COMMAND = \"curl -L \\\"https://app.roboflow.com/ds/7WiwxYZewU?key=8szFkSB8H7\\\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip\" #@param {type:\"string\"}\n",
        "!cd dataset && {DOWNLOAD_COMMAND} %% cd .. \n"
      ],
      "metadata": {
        "id": "HKpMfz4uTlbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tf_slim as slim\n",
        "eval = slim.evaluation.evaluate_once"
      ],
      "metadata": {
        "id": "4Yra4nUNHxok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from converter import _convert_dataset, _get_filenames_and_classes\n",
        "\n",
        "photos, ids = _get_filenames_and_classes('/content/train')\n",
        "_convert_dataset(photos, ids, 'converted_train')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivhWFf7bvfbm",
        "outputId": "b2e0f251-9e79-4e8c-da64-b60329fc9ee9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "r\"\"\"Downloads and converts Flowers data to TFRecords of TF-Example protos.\n",
        "\n",
        "This module downloads the Flowers data, uncompresses it, reads the files\n",
        "that make up the Flowers data and creates two TFRecord datasets: one for train\n",
        "and one for test. Each TFRecord dataset is comprised of a set of TF-Example\n",
        "protocol buffers, each of which contain a single image and label.\n",
        "\n",
        "The script should take about a minute to run.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import math\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import tensorflow.compat.v1 as tf\n",
        "\n",
        "# The number of shards per dataset split.\n",
        "_NUM_SHARDS = 5\n",
        "\n",
        "\n",
        "class ImageReader(object):\n",
        "  \"\"\"Helper class that provides TensorFlow image coding utilities.\"\"\"\n",
        "\n",
        "  def __init__(self):\n",
        "    # Initializes function that decodes RGB JPEG data.\n",
        "    self._decode_jpeg_data = tf.placeholder(dtype=tf.string)\n",
        "    self._decode_jpeg = tf.image.decode_jpeg(self._decode_jpeg_data, channels=3)\n",
        "\n",
        "  def read_image_dims(self, sess, image_data):\n",
        "    image = self.decode_jpeg(sess, image_data)\n",
        "    return image.shape[0], image.shape[1]\n",
        "\n",
        "  def decode_jpeg(self, sess, image_data):\n",
        "    image = sess.run(self._decode_jpeg,\n",
        "                     feed_dict={self._decode_jpeg_data: image_data})\n",
        "    assert len(image.shape) == 3\n",
        "    assert image.shape[2] == 3\n",
        "    return image\n",
        "\n",
        "\n",
        "def _get_filenames_and_classes(dataset_dir):\n",
        "  \"\"\"Returns a list of filenames and inferred class names.\n",
        "\n",
        "  Args:\n",
        "    dataset_dir: A directory containing a set of subdirectories representing\n",
        "      class names. Each subdirectory should contain PNG or JPG encoded images.\n",
        "\n",
        "  Returns:\n",
        "    A list of image file paths, relative to `dataset_dir` and the list of\n",
        "    subdirectories, representing class names.\n",
        "  \"\"\"\n",
        "  directories = []\n",
        "  class_names = []\n",
        "  for filename in os.listdir(dataset_dir):\n",
        "    path = os.path.join(dataset_dir, filename)\n",
        "    if os.path.isdir(path):\n",
        "      directories.append(path)\n",
        "      class_names.append(filename)\n",
        "\n",
        "  photo_filenames = []\n",
        "  for directory in directories:\n",
        "    for filename in os.listdir(directory):\n",
        "      path = os.path.join(directory, filename)\n",
        "      photo_filenames.append(path)\n",
        "\n",
        "  return photo_filenames, sorted(class_names)\n",
        "\n",
        "\n",
        "def _get_dataset_filename(dataset_dir, shard_id):\n",
        "  output_filename = 'mpox_%05d-of-%05d.tfrecord' % (\n",
        "    shard_id, _NUM_SHARDS)\n",
        "  return os.path.join(dataset_dir, output_filename)\n",
        "\n",
        "\n",
        "def _convert_dataset(filenames, class_names_to_ids, dataset_dir):\n",
        "  \"\"\"Converts the given filenames to a TFRecord dataset.\n",
        "\n",
        "  Args:\n",
        "    filenames: A list of absolute paths to png or jpg images.\n",
        "    class_names_to_ids: A dictionary from class names (strings) to ids\n",
        "      (integers).\n",
        "    dataset_dir: The directory where the converted datasets are stored.\n",
        "  \"\"\"\n",
        "  num_per_shard = int(math.ceil(len(filenames) / float(_NUM_SHARDS)))\n",
        "\n",
        "  with tf.Graph().as_default():\n",
        "    image_reader = ImageReader()\n",
        "\n",
        "    with tf.Session('') as sess:\n",
        "\n",
        "      for shard_id in range(_NUM_SHARDS):\n",
        "        output_filename = _get_dataset_filename(\n",
        "            dataset_dir, shard_id)\n",
        "\n",
        "        with tf.python_io.TFRecordWriter(output_filename) as tfrecord_writer:\n",
        "          start_ndx = shard_id * num_per_shard\n",
        "          end_ndx = min((shard_id+1) * num_per_shard, len(filenames))\n",
        "          for i in range(start_ndx, end_ndx):\n",
        "            sys.stdout.write('\\r>> Converting image %d/%d shard %d' % (\n",
        "                i+1, len(filenames), shard_id))\n",
        "            sys.stdout.flush()\n",
        "\n",
        "            # Read the filename:\n",
        "            image_data = tf.gfile.GFile(filenames[i], 'rb').read()\n",
        "            height, width = image_reader.read_image_dims(sess, image_data)\n",
        "\n",
        "            class_name = os.path.basename(os.path.dirname(filenames[i]))\n",
        "            class_id = class_names_to_ids[class_name]\n",
        "\n",
        "            # example = dataset_utils.image_to_tfexample(\n",
        "            #     image_data, b'jpg', height, width, class_id)\n",
        "            # tfrecord_writer.write(example.SerializeToString())\n",
        "\n",
        "  sys.stdout.write('\\n')\n",
        "  sys.stdout.flush()"
      ],
      "metadata": {
        "id": "a83vbBx23CTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Selected_model = \"Resnet\" #@param [\"Resnet\", \"VGG\", \"Mobilenet\"]\n",
        "\n",
        "MODEL_LIST = {\n",
        "    \"Resnet\" : \"http://download.tensorflow.org/models/resnet_v1_50_2016_08_28.tar.gz\",\n",
        "    \"VGG\" : \"http://download.tensorflow.org/models/vgg_16_2016_08_28.tar.gz\",\n",
        "    \"Mobilenet\" : \"https://storage.googleapis.com/mobilenet_v2/checkpoints/mobilenet_v2_1.4_224.tgz\"\n",
        "}\n",
        "\n",
        "MODEL_NAME = Selected_model\n",
        "MODEL_LINK = MODEL_LIST[Selected_model]\n",
        "PRETRAINED_NAME = MODEL_LINK[MODEL_LINK.index(MODEL_NAME[0 : 2].lower()) : MODEL_LINK.index('.tar')]"
      ],
      "metadata": {
        "id": "I75iLjw1Jbuc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget {model}\n",
        "!tar -zxvf {PRETRAINED_NAME + \".tar.gz\"}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVklYGMmRNQP",
        "outputId": "0e260578-c9e3-45ed-bff9-58d5246a9891"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-30 17:59:22--  http://%7Bmodel%7D/\n",
            "Resolving {model} ({model})... failed: Name or service not known.\n",
            "wget: unable to resolve host address ‘{model}’\n",
            "tar (child): resnet_v1_50_2016_08_28.tar.gz: Cannot open: No such file or directory\n",
            "tar (child): Error is not recoverable: exiting now\n",
            "tar: Child returned status 2\n",
            "tar: Error is not recoverable: exiting now\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp dataset/test/*.tfrecord dataset/compiled/test.tfrecord\n",
        "!cp dataset/train/*.tfrecord dataset/compiled/train.tfrecord\n",
        "!cp dataset/valid/*.tfrecord dataset/compiled/valid.tfrecord\n",
        "!cp dataset/train/*.pbtxt dataset/compiled/labels.pbtxt\n",
        "\n",
        "TEST_FILE = COMPILED_DIR + \"/test.tfrecord\"\n",
        "TRAIN_FILE = COMPILED_DIR + \"/train.tfrecord\"\n",
        "VALID_FILE = COMPILED_DIR + \"/valid.tfrecord\"\n",
        "LABELS_FILE = COMPILED_DIR + \"/labels.pbtxt\""
      ],
      "metadata": {
        "id": "NXozaDfw0Mmv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pjNkGJ28GW1B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}